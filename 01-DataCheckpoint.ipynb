{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "This is a modified [CRediT taxonomy of contributions](https://credit.niso.org). For each group member please list how they contributed to this project using these terms:\n",
    "> Analysis, Background Research, Conceptualization, Data Curation, Experimental Investigation, Methodology, Project Administration, Software, Visualization, Writing – Original Draft, Writing – Review & Editing\n",
    "\n",
    "- Justin Bourdlaies: Background Research, Experimental Investigation\n",
    "- Zee Avila: Project Administration, Experimental Investigation\n",
    "- Lance Mendoza: Conceptualization, Visualization, Methodology\n",
    "- Jefferson Umanzor Urrutia: Data curation, Software, Writing - Review & Editing\n",
    "- Majd Abu-Shamiyeh: Writing - Original Draft, Writing - Review & Editing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To what extent does an NBA player’s height (in inches) predict points scored per 36 minutes during the 2025-2026 NBA regular season? After testing for position and other key performance metrics such as usage rate and field goal attempts, how does height, measured by its partial R² contribution within a multiple regression model, vary across player positions and over time?\n",
    "\n",
    "Additionally, how do scoring patterns, including shot attempts and efficiency, differ across height groups, and has the relationship between height and scoring efficiency changed across recent NBA seasons?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Player physical attributes, particularly height, have long played a central role in how basketball players are evaluated and used at the professional level. In the NBA, height strongly influences positional assignment and on-court responsibilities. Taller players are more likely to occupy interior positions such as center or power forward, where responsibilities emphasize rebounding, rim protection, and screening rather than high-volume scoring. Shorter players, especially guards, are typically more involved in ball handling and shot creation. Because of this specialization, height may be indirectly related to scoring output through role differences rather than scoring ability alone. This is further supported by the fact that players in the top height/weight category with low experience were mostly categorized by \"two-point field goals\", \"offensive and defensive rebounds\", \"blocks\", and \"fouls\".<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1)\n",
    "\n",
    "Prior basketball analytics research has shown that scoring output varies substantially by position, which is closely correlated with height. Analyses of NBA data indicate that guards and wings tend to score more points per minute than forwards and centers due to higher usage rates and greater involvement in offensive actions. While the modern NBA has become more positionless, height still affects how players are used offensively, with taller players generally contributing less to scoring volume and more to non-scoring tasks. As stated in the Southwest Journal, \"height remains a factor, but not the only one dictating a player's role\".<a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2)\n",
    "\n",
    "Academic research has also examined the relationship between player anthropometrics and performance statistics. NBA player height and weight in relation to box score metrics and found that height was strongly associated with rebounding and shot blocking, but had a weaker and often negative relationship with scoring when controlling for playing time.<a name=\"cite_ref-3\"></a>[<sup>3</sup>](#cite_note-3)\n",
    "\n",
    "Modern basketball analytics frequently normalize scoring by playing time using metrics such as points per 36 minutes to allow fair comparisons across players with different minute allocations. NBA statistical documentation recommends per-minute or per-possession metrics when evaluating player production.<a name=\"cite_ref-4\"></a>[<sup>4</sup>](#cite_note-4) Community-driven analytics projects using publicly available NBA data have applied regression models to examine how physical attributes relate to scoring and often find that variables such as usage rate and offensive role explain much more variance than height alone. However, we aim to see how height can influence performance as well where these previous studies have fallen short on exploring.\n",
    "\n",
    "This project builds on prior work by focusing specifically on the relationship between player height and points scored per 36 minutes during a single modern NBA season. By treating height as a continuous variable and measuring both statistical significance and variance explained, this analysis aims to determine whether height has a meaningful independent effect on scoring rate or whether its impact is small relative to other factors.\n",
    "\n",
    "References\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1)\n",
    "Zhang, S., Lorenzo, A., Gómez, M., Mateus N., Gonçalves, B., Sampaio, J. (20 Apr 2018) Clustering performances in the NBA according to players' anthropometric attributes and playing experience. *PubMed*. https://pubmed.ncbi.nlm.nih.gov/29676222/\n",
    "\n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2)\n",
    "Ilic S. (12 Feb 2024) Average NBA Height By Position 2024: How They Measure Up?. *Southwest Journal*. https://www.southwestjournal.com/sport/nba/average-nba-height-by-position/\n",
    "\n",
    "3. <a name=\"cite_note-3\"></a> [^](#cite_ref-3)\n",
    "Yixiong, C., Liu, F., Bao, D., Liu, H., Zhang, S., Gómez, M. (21 Oct 2019) Key Anthropometric and Physical Determinants for Different Playing Positions During National Basketball Association Draft Combine Test. *Frontiers*. https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2019.02359/full\n",
    "\n",
    "4. <a name=\"cite_note-4\"></a> [^](#cite_ref-4)\n",
    "Wikipedia (19 Jul 2022) Player efficiency rating: Revision history. *Wikipedia*. https://en.wikipedia.org/wiki/Player_efficiency_rating"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We predict that there will be a significant relationship between an NBA player's height and their points scored per 36 minutes. We expect taller players to score slightly fewer points per 36 minutes on average. This is because taller players have different roles such as defending and rebounding which can prevent them from focusing on attacking and scoring. We also predict that height will only have a small impact on the variance in scoring rate."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "Instructions: REPLACE the contents of this cell with descriptions of your actual datasets.\n",
    "\n",
    "DATA:\n",
    "\n",
    "Link: https://www.nba.com/stats/players/bio\n",
    "\n",
    "Link: https://www.nbastuffer.com/2025-2026-nba-player-stats/\n",
    "\n",
    "### Dataset #1: NBA 2025–26 Player Bio and Performance Overview\n",
    "\n",
    "The data consists of biographical and performance context data for players in the NBA 2025-2026 regular season at the player level. Each row symbolizes each player, identified by player_id, and with a few demographic data, age, height, weight, college, country and team abbreviation. Along with biographical data, the dataset will contain performance_related statistics, including points per game (pts), rebounds (reb), assists (ast), usage percentage (usg_pct), true shooting percentage (ts_pct), assist percentage (ast_pct) and net rating (net_rating). Height is presented as both formatted (feet inches) and as a numeric variable (player_height_inches) which is measured in inches and can be analyzed mathematically. \n",
    "\n",
    "The data has 532 players and 23 attributes (columns), given the fact that there is one row per player_id, it is clear that the data is tidy and uniquely indexed. Missingness is minimal with few missing values in variables such as player weight and draft number. Most of the performance variables appear complete, this facilitates sound analysis of player-level trends. The range of height values fall within a realistic range for professional basketball players suggesting there are no extreme outliers in this key variable.\n",
    "\n",
    "A limitation in this data set would be the absence of total minutes played. Considering some metrics such as points per 36 minutes entail total minutes, a second dataset containing minutes (MIN) and total points (PTS) will be merged using player_id. Additionally, because the data is derived from official NBA sources and specifically limited to the 2025-2026 season, it only reflects players who featured in that season and may not provide insights into broader historical trends.\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1\n",
    "  - Dataset Name: NBA.com LeagueDashPlayerBioStats 2025–26 Regular Season\n",
    "  - Link to the dataset: https://www.nba.com/stats/players/bio\n",
    "  - Number of observations: 532 rows, one row per player\n",
    "  - Number of variables: 23 columns\n",
    "  - Description of the variables most relevant to this project\n",
    "    - We use `PLAYER_ID` and `PLAYER_NAME` to identify players. Height is provided as `PLAYER_HEIGHT_INCHES` in inches. We also use context variables such as `TEAM_ABBREVIATION`, `AGE`, and performance context variables like `USG_PCT` and `TS_PCT`\n",
    "  - Descriptions of any shortcomings this dataset has with repsect to the project\n",
    "    - This dataset does not include total minutes played, so we cannot compute points per 36 minutes from it alone. It is also season-to-date unless we specify a cutoff date for when the data were pulled\n",
    "- Dataset #2 (if you have more than one!)\n",
    "  - same as above\n",
    "- etc\n",
    "\n",
    "Each dataset deserves either a set of bullet points as above or a few sentences if you prefer that method.\n",
    "\n",
    "If you plan to use multiple datasets, add a few sentences about how you plan to combine these datasets.\n",
    "- We will compute `points_per_36 = PTS / MIN * 36` using Dataset 2, then merge Dataset 2 with Dataset 1 on `PLAYER_ID` to attach height to the per-36 scoring data. The final merged dataset will be written to nba_2025_26_merged.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Download Progress:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Download Progress:  50%|█████     | 1/2 [00:00<00:00,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: nba_com_players_bio_2025_26.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Download Progress: 100%|██████████| 2/2 [00:00<00:00,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: bad-drivers.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/airline-safety/airline-safety.csv', 'filename':'airline-safety.csv'},\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/bad-drivers/bad-drivers.csv', 'filename':'bad-drivers.csv'}\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #1 \n",
    "\n",
    "Instructions: \n",
    "1. Change the header from Dataset #1 to something more descriptive of the dataset\n",
    "2. Write a few paragraphs about this dataset. Make sure to cover\n",
    "   1. Describe the important metrics, what units they are in, and giv some sense of what they mean.  \n",
    "   - This dataset comes from the NBA stats player bio table for the 2025–26 regular season. Each row represents one player, and the dataset includes identifiers and basic bio attributes along with a small set of performance context metrics.\n",
    "   - The main variable we need from this dataset is height. Height appears both as a formatted string (feet-inches) and as `PLAYER_HEIGHT_INCHES`, which is already provided in inches and can be used directly in analysis. Other useful context variables include `TEAM_ABBREVIATION`, `AGE`, and role or efficiency proxies such as `USG_PCT` and `TS_PCT`.\n",
    "   2. If there are any major concerns with the dataset, describe them. \n",
    "   - A key limitation for our project is that this bio dataset does not include minutes played. Because points per 36 minutes requires total minutes, we will use a second dataset that includes `MIN` and `PTS` totals and then merge the two datasets using `PLAYER_ID`.\n",
    "3. Use the cell below to \n",
    "    1. load the dataset \n",
    "    2. make the dataset tidy or demonstrate that it was already tidy\n",
    "    3. demonstrate the size of the dataset\n",
    "    4. find out how much data is missing, where its missing, and if its missing at random or seems to have any systematic relationships in its missingness\n",
    "    5. find and flag any outliers or suspicious entries\n",
    "    6. clean the data or demonstrate that it was already clean.  You may choose how to deal with missingness (dropna of fillna... how='any' or 'all') and you should justify your choice in some way\n",
    "    7. You will load raw data from `data/00-raw/`, you will (optionally) write intermediate stages of your work to `data/01-interim` and you will write the final fully wrangled version of your data to `data/02-processed`\n",
    "4. Optionally you can also show some summary statistics for variables that you think are important to the project\n",
    "5. Feel free to add more cells here if that's helpful for you\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 shape: (532, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_id</th>\n",
       "      <th>player_name</th>\n",
       "      <th>team_id</th>\n",
       "      <th>team_abbreviation</th>\n",
       "      <th>age</th>\n",
       "      <th>player_height</th>\n",
       "      <th>player_height_inches</th>\n",
       "      <th>player_weight</th>\n",
       "      <th>college</th>\n",
       "      <th>country</th>\n",
       "      <th>...</th>\n",
       "      <th>gp</th>\n",
       "      <th>pts</th>\n",
       "      <th>reb</th>\n",
       "      <th>ast</th>\n",
       "      <th>net_rating</th>\n",
       "      <th>oreb_pct</th>\n",
       "      <th>dreb_pct</th>\n",
       "      <th>usg_pct</th>\n",
       "      <th>ts_pct</th>\n",
       "      <th>ast_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1630639</td>\n",
       "      <td>A.J. Lawson</td>\n",
       "      <td>1610612761</td>\n",
       "      <td>TOR</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6-6</td>\n",
       "      <td>78</td>\n",
       "      <td>179</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>Canada</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-14.4</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1631260</td>\n",
       "      <td>AJ Green</td>\n",
       "      <td>1610612749</td>\n",
       "      <td>MIL</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6-4</td>\n",
       "      <td>76</td>\n",
       "      <td>190</td>\n",
       "      <td>Northern Iowa</td>\n",
       "      <td>USA</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>10.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1642358</td>\n",
       "      <td>AJ Johnson</td>\n",
       "      <td>1610612742</td>\n",
       "      <td>DAL</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6-5</td>\n",
       "      <td>77</td>\n",
       "      <td>160</td>\n",
       "      <td>None</td>\n",
       "      <td>USA</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>203932</td>\n",
       "      <td>Aaron Gordon</td>\n",
       "      <td>1610612743</td>\n",
       "      <td>DEN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6-8</td>\n",
       "      <td>80</td>\n",
       "      <td>235</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>USA</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>17.7</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1628988</td>\n",
       "      <td>Aaron Holiday</td>\n",
       "      <td>1610612745</td>\n",
       "      <td>HOU</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6-0</td>\n",
       "      <td>72</td>\n",
       "      <td>185</td>\n",
       "      <td>UCLA</td>\n",
       "      <td>USA</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   player_id    player_name     team_id team_abbreviation   age player_height  \\\n",
       "0    1630639    A.J. Lawson  1610612761               TOR  25.0           6-6   \n",
       "1    1631260       AJ Green  1610612749               MIL  26.0           6-4   \n",
       "2    1642358     AJ Johnson  1610612742               DAL  21.0           6-5   \n",
       "3     203932   Aaron Gordon  1610612743               DEN  30.0           6-8   \n",
       "4    1628988  Aaron Holiday  1610612745               HOU  29.0           6-0   \n",
       "\n",
       "   player_height_inches player_weight         college country  ...  gp   pts  \\\n",
       "0                    78           179  South Carolina  Canada  ...  13   3.8   \n",
       "1                    76           190   Northern Iowa     USA  ...  49  10.7   \n",
       "2                    77           160            None     USA  ...  28   2.5   \n",
       "3                    80           235         Arizona     USA  ...  23  17.7   \n",
       "4                    72           185            UCLA     USA  ...  35   5.7   \n",
       "\n",
       "   reb  ast  net_rating  oreb_pct  dreb_pct  usg_pct  ts_pct  ast_pct  \n",
       "0  1.8  0.2       -14.4     0.056     0.160    0.186   0.545    0.045  \n",
       "1  2.6  2.0        -0.2     0.008     0.076    0.128   0.643    0.088  \n",
       "2  1.1  0.8        -3.8     0.032     0.104    0.197   0.375    0.147  \n",
       "3  6.2  2.5        14.0     0.047     0.162    0.228   0.632    0.130  \n",
       "4  0.9  1.0         3.8     0.012     0.049    0.173   0.570    0.103  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One row per player_id: True\n",
      "Missing player_name: 0\n",
      "Top missing counts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "player_weight    6\n",
       "draft_number     1\n",
       "player_id        0\n",
       "ts_pct           0\n",
       "usg_pct          0\n",
       "dreb_pct         0\n",
       "oreb_pct         0\n",
       "net_rating       0\n",
       "ast              0\n",
       "reb              0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top missing fractions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "player_weight    0.011278\n",
       "draft_number     0.001880\n",
       "player_id        0.000000\n",
       "ts_pct           0.000000\n",
       "usg_pct          0.000000\n",
       "dreb_pct         0.000000\n",
       "oreb_pct         0.000000\n",
       "net_rating       0.000000\n",
       "ast              0.000000\n",
       "reb              0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    532.000000\n",
       "mean      78.588346\n",
       "std        3.292647\n",
       "min       67.000000\n",
       "25%       76.000000\n",
       "50%       79.000000\n",
       "75%       81.000000\n",
       "max       88.000000\n",
       "Name: player_height_inches, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote processed Dataset 1 to data/02-processed/nba_com_bio_2025_26_processed.csv\n",
      "Reloaded shape: (532, 23)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "RAW_DIR = Path(\"data/00-raw\")\n",
    "PROC_DIR = Path(\"data/02-processed\")\n",
    "PROC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def nba_resultset_to_df(json_path, resultset_index=0):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        obj = json.load(f)\n",
    "    rs = obj[\"resultSets\"][resultset_index]\n",
    "    df = pd.DataFrame(rs[\"rowSet\"], columns=rs[\"headers\"])\n",
    "    df.columns = [c.strip().lower() for c in df.columns]\n",
    "    return df, obj\n",
    "\n",
    "bio_path = RAW_DIR / \"nba_com_players_bio_2025_26.json\"\n",
    "bio, bio_meta = nba_resultset_to_df(bio_path)\n",
    "\n",
    "print(\"Dataset 1 shape:\", bio.shape)\n",
    "display(bio.head())\n",
    "\n",
    "# Tidy check\n",
    "print(\"One row per player_id:\", bio[\"player_id\"].is_unique)\n",
    "print(\"Missing player_name:\", bio[\"player_name\"].isna().sum())\n",
    "\n",
    "# Convert important columns to numeric\n",
    "num_cols = [\"player_height_inches\", \"age\", \"gp\", \"pts\", \"reb\", \"ast\", \"usg_pct\", \"ts_pct\", \"ast_pct\", \"net_rating\"]\n",
    "for c in num_cols:\n",
    "    if c in bio.columns:\n",
    "        bio[c] = pd.to_numeric(bio[c], errors=\"coerce\")\n",
    "\n",
    "# Missingness\n",
    "missing_counts = bio.isna().sum().sort_values(ascending=False)\n",
    "missing_fracs = bio.isna().mean().sort_values(ascending=False)\n",
    "\n",
    "print(\"Top missing counts\")\n",
    "display(missing_counts.head(10))\n",
    "\n",
    "print(\"Top missing fractions\")\n",
    "display(missing_fracs.head(10))\n",
    "\n",
    "# Outliers and suspicious values\n",
    "if \"player_height_inches\" in bio.columns:\n",
    "    display(bio[\"player_height_inches\"].describe())\n",
    "    suspicious_height = bio[(bio[\"player_height_inches\"] < 65) | (bio[\"player_height_inches\"] > 90)]\n",
    "    if len(suspicious_height) > 0:\n",
    "        display(suspicious_height[[\"player_name\", \"player_height\", \"player_height_inches\"]].head(30))\n",
    "\n",
    "# Save processed dataset 1\n",
    "bio_out = PROC_DIR / \"nba_com_bio_2025_26_processed.csv\"\n",
    "bio.to_csv(bio_out, index=False)\n",
    "print(\"Wrote processed Dataset 1 to\", bio_out)\n",
    "\n",
    "# Reload to confirm write succeeded\n",
    "bio_reload = pd.read_csv(bio_out)\n",
    "print(\"Reloaded shape:\", bio_reload.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #2 \n",
    "\n",
    "See instructions above for Dataset #1.  Feel free to keep adding as many more datasets as you need.  Put each new dataset in its own section just like these. \n",
    "\n",
    "Lastly if you do have multiple datasets, add another section where you demonstrate how you will join, align, cross-reference or whatever to combine data from the different datasets\n",
    "\n",
    "Please note that you can always keep adding more datasets in the future if these datasets you turn in for the checkpoint aren't sufficient.  The goal here is demonstrate that you can obtain and wrangle data.  You are not tied down to only use what you turn in right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(588, 30)\n",
      "   RANK                     NAME TEAM CUR  POS   AGE  GP   MpG  USG%   TO%  \\\n",
      "0   NaN              Luka Doncic  Lal   *  F-G  27.0  42  35.5  37.9  16.2   \n",
      "1   NaN  Shai Gilgeous-Alexander  Okc   *    G  27.6  49  33.3  33.5   9.6   \n",
      "2   NaN          Anthony Edwards  Min   *    G  24.5  46  35.5  31.2  11.6   \n",
      "3   NaN             Jaylen Brown  Bos   *  G-F  29.3  49  34.2  36.9  13.7   \n",
      "4   NaN         Donovan Mitchell  Cle   *    G  29.4  51  33.7  32.6  13.0   \n",
      "\n",
      "   ...  ApG  SpG  BpG  TOpG   P+R   P+A  P+R+A    VI   ORtg   DRtg  \n",
      "0  ...  8.5  1.5  0.5   4.3  40.7  41.4   49.2  14.6  119.9  110.7  \n",
      "1  ...  6.4  1.3  0.8   2.1  36.2  38.2   42.7  11.6  134.5  106.4  \n",
      "2  ...  3.7  1.3  0.8   2.7  34.5  33.0   38.2   9.3  119.4  111.9  \n",
      "3  ...  4.7  1.0  0.4   3.6  36.1  34.0   40.8  11.5  113.3  107.9  \n",
      "4  ...  5.9  1.5  0.3   3.1  33.5  34.9   39.4  10.9  120.6  111.3  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Dataset 2's file path and dataframe\n",
    "dataset_two_file_path = \"data/00-raw/2025-2026 NBA Player Stats - NBAstuffer.csv\"\n",
    "dataset_two_player_stats = pd.read_csv(dataset_two_file_path)\n",
    "\n",
    "# Dataset 2's shape and head\n",
    "print(dataset_two_player_stats.shape)\n",
    "print(dataset_two_player_stats.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rank', 'name', 'team', 'cur', 'pos', 'age', 'gp', 'mpg', 'usgpct',\n",
      "       'topct', 'fta', 'ftpct', '2pa', '2ppct', '3pa', '3ppct', 'efgpct',\n",
      "       'tspct', 'ppg', 'rpg', 'apg', 'spg', 'bpg', 'topg', 'p+r', 'p+a',\n",
      "       'p+r+a', 'vi', 'ortg', 'drtg'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Clean column names\n",
    "dataset_two_player_stats.columns = (dataset_two_player_stats.columns.str.lower().str.replace(\" \", \"_\").str.replace(\"%\", \"pct\"))\n",
    "print(dataset_two_player_stats.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(588, 29)\n"
     ]
    }
   ],
   "source": [
    "# Check if data is tidy (drop completely empty columns and remove repeated header rows if any)\n",
    "dataset_two_player_stats = dataset_two_player_stats.dropna(axis=1, how=\"all\")\n",
    "dataset_two_player_stats = dataset_two_player_stats[dataset_two_player_stats.iloc[:,0] != dataset_two_player_stats.columns[0]]\n",
    "\n",
    "# Show dataset size after cleaning\n",
    "print(dataset_two_player_stats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name       0\n",
      "team       0\n",
      "cur       56\n",
      "pos        0\n",
      "age        0\n",
      "gp         0\n",
      "mpg        0\n",
      "usgpct     0\n",
      "topct      0\n",
      "fta        0\n",
      "ftpct      0\n",
      "2pa        0\n",
      "2ppct      0\n",
      "3pa        0\n",
      "3ppct      0\n",
      "efgpct     0\n",
      "tspct      0\n",
      "ppg        0\n",
      "rpg        0\n",
      "apg        0\n",
      "spg        0\n",
      "bpg        0\n",
      "topg       0\n",
      "p+r        0\n",
      "p+a        0\n",
      "p+r+a      0\n",
      "vi         0\n",
      "ortg       0\n",
      "drtg       0\n",
      "dtype: int64\n",
      "name      0.0000\n",
      "team      0.0000\n",
      "cur       0.0952\n",
      "pos       0.0000\n",
      "age       0.0000\n",
      "gp        0.0000\n",
      "mpg       0.0000\n",
      "usgpct    0.0000\n",
      "topct     0.0000\n",
      "fta       0.0000\n",
      "ftpct     0.0000\n",
      "2pa       0.0000\n",
      "2ppct     0.0000\n",
      "3pa       0.0000\n",
      "3ppct     0.0000\n",
      "efgpct    0.0000\n",
      "tspct     0.0000\n",
      "ppg       0.0000\n",
      "rpg       0.0000\n",
      "apg       0.0000\n",
      "spg       0.0000\n",
      "bpg       0.0000\n",
      "topg      0.0000\n",
      "p+r       0.0000\n",
      "p+a       0.0000\n",
      "p+r+a     0.0000\n",
      "vi        0.0000\n",
      "ortg      0.0000\n",
      "drtg      0.0000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check missing counts per column and missing percent per column\n",
    "print(dataset_two_player_stats.isna().sum())\n",
    "print(dataset_two_player_stats.isna().mean().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mpg    float64\n",
      "ppg    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert key columns to numeric values and check their types after\n",
    "numeric_cols = [\"mpg\", \"ppg\"]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if col in dataset_two_player_stats.columns:\n",
    "        dataset_two_player_stats[col] = pd.to_numeric(dataset_two_player_stats[col], errors=\"coerce\")\n",
    "\n",
    "print(dataset_two_player_stats[numeric_cols].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    588.000000\n",
      "mean      15.234179\n",
      "std        6.533287\n",
      "min        0.000000\n",
      "25%       11.215812\n",
      "50%       14.683282\n",
      "75%       18.523216\n",
      "max       55.384615\n",
      "Name: points_per_36, dtype: float64\n",
      "     points_per_36   ppg   mpg\n",
      "528      55.384615   2.0   1.3\n",
      "471      38.571429   3.0   2.8\n",
      "44       35.108911  19.7  20.2\n",
      "7        34.520548  28.0  29.2\n",
      "1        34.378378  31.8  33.3\n",
      "26       33.311203  22.3  24.1\n",
      "0        33.261972  32.8  35.5\n",
      "376      32.727273   5.0   5.5\n",
      "9        31.284345  27.2  31.3\n",
      "4        30.979228  29.0  33.7\n",
      "3        30.842105  29.3  34.2\n",
      "84       30.830769  16.7  19.5\n",
      "8        30.621951  27.9  32.8\n",
      "12       30.594249  26.6  31.3\n",
      "21       30.289655  24.4  29.0\n"
     ]
    }
   ],
   "source": [
    "# Compute points_per_36\n",
    "if \"ppg\" in dataset_two_player_stats.columns and \"mpg\" in dataset_two_player_stats.columns:\n",
    "    dataset_two_player_stats[\"points_per_36\"] = (dataset_two_player_stats[\"ppg\"] / dataset_two_player_stats[\"mpg\"]) * 36\n",
    "\n",
    "    print(dataset_two_player_stats[\"points_per_36\"].describe())\n",
    "\n",
    "    print(dataset_two_player_stats.sort_values(\"points_per_36\", ascending=False)[[\"points_per_36\", \"ppg\", \"mpg\"]].head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [name, team, cur, pos, age, gp, mpg, usgpct, topct, fta, ftpct, 2pa, 2ppct, 3pa, 3ppct, efgpct, tspct, ppg, rpg, apg, spg, bpg, topg, p+r, p+a, p+r+a, vi, ortg, drtg, points_per_36]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 30 columns]\n",
      "            name team cur pos   age  gp  mpg  usgpct  topct  fta  ...  spg  \\\n",
      "528  Isaac Jones  Det   *   F  25.6   1  1.3    63.6    0.0    0  ...  0.0   \n",
      "\n",
      "     bpg  topg  p+r  p+a  p+r+a   vi  ortg  drtg  points_per_36  \n",
      "528  0.0   0.0  2.0  2.0    2.0  0.0   0.0   0.0      55.384615  \n",
      "\n",
      "[1 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Outlier checks\n",
    "print(dataset_two_player_stats[dataset_two_player_stats[\"mpg\"] > 48])\n",
    "\n",
    "print(dataset_two_player_stats[dataset_two_player_stats[\"points_per_36\"] > 40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(587, 30)\n"
     ]
    }
   ],
   "source": [
    "# Remove the extreme rows\n",
    "dataset_two_player_stats = dataset_two_player_stats[dataset_two_player_stats[\"points_per_36\"] <= 40]\n",
    "\n",
    "print(dataset_two_player_stats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned dataset\n",
    "output_path = \"data/02-processed/NBAstuffer_2025_26_processed.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned dataset to: data/02-processed/NBAstuffer_2025_26_processed.csv\n"
     ]
    }
   ],
   "source": [
    "# Save directly\n",
    "dataset_two_player_stats.to_csv(output_path, index=False)\n",
    "print(\"Saved cleaned dataset to:\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded shape: (587, 30)\n"
     ]
    }
   ],
   "source": [
    "# Reload to confirm\n",
    "df_check = pd.read_csv(output_path)\n",
    "print(\"Reloaded shape:\", df_check.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics \n",
    "\n",
    "Instructions: Keep the contents of this cell. For each item on the checklist\n",
    "-  put an X there if you've considered the item\n",
    "-  IF THE ITEM IS RELEVANT place a short paragraph after the checklist item discussing the issue.\n",
    "  \n",
    "Items on this checklist are meant to provoke discussion among good-faith actors who take their ethical responsibilities seriously. Your teams will document these discussions and decisions for posterity using this section.  You don't have to solve these problems, you just have to acknowledge any potential harm no matter how unlikely.\n",
    "\n",
    "Here is a [list of real world examples](https://deon.drivendata.org/examples/) for each item in the checklist that can refer to.\n",
    "\n",
    "[![Deon badge](https://img.shields.io/badge/ethics%20checklist-deon-brightgreen.svg?style=popout-square)](http://deon.drivendata.org/)\n",
    "\n",
    "### A. Data Collection\n",
    " - [X] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    "       \n",
    "> Data collected is publicly available public athlete performance data, with no direct human subjects interaction.\n",
    "\n",
    " - [X] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    "\n",
    "> Points per 36 minutes was chosen to represent a substantial amount of playing time (approximately three quarters of a game), but may still inflate scoring rates for players with limited minutes or specific roles. We can begin to mitigate such bias by acknowledging the limitations of points per 36 minutes and interpreting results cautiously rather than as definitive measures of scoring ability.\n",
    "\n",
    " - [X] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    "\n",
    "> We can limit PII exposure by using only publicly available player statistics and collecting no personal information beyond what is  necessary for our analysis.\n",
    "\n",
    " - [X] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    "\n",
    "> We are not collecting protected attributes (race/gender), so downstream bias testing by protected group is not possible with our data. We will avoid claims about such groups.\n",
    "\n",
    "### B. Data Storage\n",
    " - [X] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    "\n",
    "> The data are public and not sensitive. We will not store passwords, keys, or any private information in the repo.\n",
    "\n",
    " - [X] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    "\n",
    "> The data collected is publicly available and non-sensitive. However, individual records could be removed from future analyses upon request.\n",
    "\n",
    " - [X] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "\n",
    "> The data are publicly available and non-sensitive, so they may be retained for reproducibility and future reference.\n",
    "\n",
    "### C. Analysis\n",
    " - [X] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    "\n",
    "> We were mindful of potential blindspots in a statistical approach. We confirmed our assumptions using basic basketball context, such as player roles and how scoring opportunities may vary by position and team system.\n",
    "\n",
    " - [X] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    "\n",
    "> The dataset may reflect bias due to imbalanced height distributions across positions and survivorship bias, as only players who reached the NBA are included. We can mitigate potential bias by framing height as one factor among many and avoiding claims about its effect on scoring.\n",
    "\n",
    " - [X] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    "> We will avoid misleading graphs and avoid claiming height causes scoring. We will show the full spread of the data and point out outliers.\n",
    "\n",
    " - [X] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    "\n",
    "> We will avoid displaying personal identifiers and instead focus on aggregate statistical relationships rather than individual players.\n",
    "\n",
    " - [X] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "\n",
    "> The analysis is documented in a version-controlled Jupyter notebook, making the steps reproducible and allowing issues to be identified and corrected if needed.\n",
    "\n",
    "### D. Modeling\n",
    " - [X] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    "\n",
    "> Height may act as a proxy for player position or role, which could lead to oversimplified interpretations of scoring ability. We will interpret results carefully and avoid oversimplified claims about height.\n",
    "\n",
    " - [X] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    " - [X] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    "\n",
    "> Points per 36 minutes was selected to standardize scoring across players and reflect meaningful playing time, though it assumes linear scaling and may not capture all in-game dynamics.\n",
    "\n",
    " - [X] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    "\n",
    "> The methods used in this analysis are straightforward and interpretable, allowing results to be explained clearly without requiring complex model explanations.\n",
    "\n",
    " - [X] **D.5 Communicate limitations**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "\n",
    "> We made an effort to clearly explain the limitations of the analysis, including potential sources of bias and the fact that results do not necessarily imply causation.\n",
    "\n",
    "### E. Deployment\n",
    " - [X] **E.1 Monitoring and evaluation**: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    "\n",
    "> Since the analysis is not deployed, ongoing monitoring is not applicable. However, future work could reassess results as new data is available.\n",
    "\n",
    " - [X] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    "\n",
    "> In the unlikely event of harm or misuse, we would review the analysis and clarify or correct the findings as needed.\n",
    "\n",
    " - [X] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    "\n",
    "> Since the analysis is not deployed, rollback is not applicable. Results could also be updated or removed if necessary.\n",
    "\n",
    " - [X] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n",
    "\n",
    "> Results could be misinterpreted to suggest that height alone determines scoring ability, so findings are presented as correlational and exploratory."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justin Bourdlaies, Zee Avila, Lance Mendoza, Jefferson Umanzor Urrutia, Majd Abu-Shamiyeh\n",
    "\n",
    "1. Check the group chat at least once a day and respond\n",
    "2. Do your assigned share of work\n",
    "3. If something comes up, discuss with the group and work can be redistributed accordingly (e.g. one person who misses work one week can help do more research the next week)\n",
    "4. If there are conflicting plans/ideas for parts of the project compromise and integrate as much of both as we can"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W7: Data Checkpoint 01 due on 18 February\n",
    "- Export season data and choose a clear cutoff date\n",
    "- Clean data and compute points per 36\n",
    "- Save processed dataset for reuse and push notebook\n",
    "\n",
    "W9: EDA Checkpoint 02 due on 6 March\n",
    "- Load processed data from data/02-processed\n",
    "- Create key EDA visuals and document patterns and outliers\n",
    "- Decide final analysis approach and push notebook\n",
    "\n",
    "W10: Final Project + Video 03 due on 18 March\n",
    "- Run final statistical analysis with controls\n",
    "- Finish figures and write discussion limitations and conclusion\n",
    "- Record video summary and push final notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
